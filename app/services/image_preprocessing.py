import cv2
import os
import json
import numpy as np
import torch
import faiss
from pathlib import Path
from google.cloud import storage
from transformers import CLIPProcessor, CLIPModel
from dotenv import load_dotenv

# Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()

# Äá»‹nh nghÄ©a cÃ¡c Ä‘Æ°á»ng dáº«n
IMAGE_DIR = "app/static/images/test_set"
PROCESSED_DIR = "app/static/processed"
INDEX_FILE = "app/static/faiss_index.bin"
PROCESSED_IMAGES_FILE = "app/static/processed_images.json"
EMBEDDED_VECTORS_FILE = "app/static/embedded_vectors.json"

# Google Cloud Storage
GCS_BUCKET = "lantn"
GCS_INDEX_PATH = "faiss_index.bin"
GCS_KEY_PATH = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")

if not GCS_KEY_PATH or not os.path.exists(GCS_KEY_PATH):
    raise FileNotFoundError("âŒ Google Cloud Key khÃ´ng tá»“n táº¡i hoáº·c chÆ°a Ä‘Æ°á»£c cáº¥u hÃ¬nh Ä‘Ãºng!")

# FAISS Index
INDEX_DIM = 512  
index = faiss.IndexFlatL2(INDEX_DIM)

# Kiá»ƒm tra thiáº¿t bá»‹ GPU hay CPU
device = "cuda" if torch.cuda.is_available() else "cpu"

# Load mÃ´ hÃ¬nh CLIP
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

# Táº¡o thÆ° má»¥c náº¿u chÆ°a cÃ³
os.makedirs(PROCESSED_DIR, exist_ok=True)

def get_all_images(directory):
    """Láº¥y danh sÃ¡ch áº£nh JPG, JPEG, PNG tá»« thÆ° má»¥c."""
    return list(Path(directory).rglob("*.jpg")) + \
           list(Path(directory).rglob("*.jpeg")) + \
           list(Path(directory).rglob("*.png"))

def load_json(file_path):
    """Táº£i dá»¯ liá»‡u tá»« JSON, tráº£ vá» set náº¿u lá»—i."""
    if os.path.exists(file_path):
        try:
            with open(file_path, "r") as f:
                return json.load(f)
        except json.JSONDecodeError:
            print(f"âš ï¸ Lá»—i Ä‘á»c file JSON: {file_path}")
    return {}

def save_json(data, file_path):
    """LÆ°u dá»¯ liá»‡u vÃ o JSON."""
    with open(file_path, "w") as f:
        json.dump(data, f)

def preprocess_image(image_path):
    """Tiá»n xá»­ lÃ½ áº£nh: Gaussian Blur, cÃ¢n báº±ng histogram, phÃ¡t hiá»‡n cáº¡nh."""
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"âŒ Lá»—i Ä‘á»c áº£nh: {image_path}")
        return None

    blurred = cv2.GaussianBlur(img, (5, 5), 0)
    equalized = cv2.equalizeHist(blurred)
    edges = cv2.Canny(equalized, 50, 150)
    return edges

def load_index():
    """Táº£i FAISS Index tá»« file náº¿u cÃ³."""
    if os.path.exists(INDEX_FILE):
        try:
            return faiss.read_index(INDEX_FILE)
        except Exception as e:
            print(f"âš ï¸ Lá»—i táº£i FAISS Index: {e}, táº¡o Index má»›i.")
    return faiss.IndexFlatL2(INDEX_DIM)

index = load_index()

def save_index():
    """LÆ°u FAISS Index vÃ o file."""
    faiss.write_index(index, INDEX_FILE)

def embed_image(image_path):
    """NhÃºng áº£nh thÃ nh vector sá»­ dá»¥ng CLIP."""
    image = cv2.imread(image_path)
    if image is None:
        print(f"âŒ Lá»—i Ä‘á»c áº£nh: {image_path}")
        return None

    inputs = processor(images=image, return_tensors="pt").to(device)
    with torch.no_grad():
        embedding = model.get_image_features(**inputs)
    
    embedding = embedding.cpu().numpy().astype(np.float32)

    if embedding.shape[1] != INDEX_DIM:
        print(f"âš ï¸ Vector nhÃºng cÃ³ shape khÃ´ng Ä‘Ãºng: {embedding.shape}")
        return None
    
    return embedding

def upload_faiss_to_gcs():
    """Upload FAISS Index lÃªn Google Cloud Storage."""
    try:
        client = storage.Client()
        bucket = client.bucket(GCS_BUCKET)
        blob = bucket.blob(GCS_INDEX_PATH)

        if os.path.exists(INDEX_FILE):
            blob.upload_from_filename(INDEX_FILE)
            print(f"âœ… FAISS Index Ä‘Ã£ Ä‘Æ°á»£c upload lÃªn GCS táº¡i: gs://{GCS_BUCKET}/{GCS_INDEX_PATH}")
        else:
            print("âŒ KhÃ´ng tÃ¬m tháº¥y FAISS Index Ä‘á»ƒ upload!")
    except Exception as e:
        print(f"âŒ Lá»—i upload FAISS Index lÃªn GCS: {e}")

def process_new_images():
    """Xá»­ lÃ½ áº£nh má»›i vÃ  nhÃºng áº£nh thÃ nh vector náº¿u chÆ°a cÃ³."""
    all_images = get_all_images(IMAGE_DIR)
    processed_vectors = load_json(EMBEDDED_VECTORS_FILE)
    new_images = [str(img) for img in all_images if str(img) not in processed_vectors]

    print(f"ğŸ“‚ Tá»•ng sá»‘ áº£nh: {len(all_images)}, áº¢nh má»›i cáº§n nhÃºng: {len(new_images)}")

    if not new_images:
        print("âœ… KhÃ´ng cÃ³ áº£nh má»›i Ä‘á»ƒ xá»­ lÃ½.")
        return
    
    for image_path in new_images:
        processed = preprocess_image(image_path)
        if processed is not None:
            output_path = Path(PROCESSED_DIR) / Path(image_path).relative_to(IMAGE_DIR)
            os.makedirs(output_path.parent, exist_ok=True)
            cv2.imwrite(str(output_path), processed)
            
            embedding = embed_image(image_path)
            if embedding is not None:
                index.add(embedding)
                processed_vectors[image_path] = embedding.flatten().tolist()
                print(f"âœ… ÄÃ£ nhÃºng vector: {image_path}")
            else:
                print(f"âŒ Lá»—i nhÃºng vector: {image_path}")

    if index.ntotal > 0:
        save_index()
        print("ğŸ’¾ ÄÃ£ lÆ°u FAISS Index.")

    save_json(processed_vectors, EMBEDDED_VECTORS_FILE)
    print("âœ… HoÃ n thÃ nh xá»­ lÃ½ vÃ  nhÃºng áº£nh má»›i.")
    
    upload_faiss_to_gcs()

if __name__ == "__main__":
    process_new_images()
